{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitdatascicondac3942d970fb941e989f3a79cc9971fc0",
   "display_name": "Python 3.7.3 64-bit ('datasci': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  UNIVARIATE METHOD \n",
    "\n",
    "This file is a port-over from Janelcy Alferes' Matlab scripts\n",
    "\n",
    "This script contains the different steps to follow to apply the univariate\n",
    "method for on-line data treatment.  It's a type script with the different\n",
    "step for an example of parameter X of a Sensor."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "import Sensors\n",
    "import FaultDetection\n",
    "import ModelCalibration\n",
    "import OutlierDetection\n",
    "import outlierdetection_Online_EWMA\n",
    "import PlottingTools\n",
    "import Smoother\n",
    "import TreatedData\n",
    "import DataCoherence\n",
    "from DefaultSettings import DefaultParam\n",
    "\n",
    "register_matplotlib_converters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Raw data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../sample_data/influent3.csv'\n",
    "raw_data = pd.read_csv(path, sep=';')\n",
    "raw_data.datetime = pd.to_datetime(raw_data.datetime)\n",
    "raw_data.set_index('datetime', inplace=True, drop=True)\n",
    "data = raw_data['15-09-2017 00:00:00':'15-04-2018 00:00:00']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a 'Sensor' object to store the data and the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = Sensors.parse_dataframe(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Pre-processed Data'\n",
    "PlottingTools.plotRaw_D_mpl(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Choose the time series to filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = sensors[0]\n",
    "channel = sensor.channels['COD']  # Variable to be filtered\n",
    "\n",
    "T0 = channel.start\n",
    "TF = channel.end"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate default parameters for the filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel.params = DefaultParam()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Example: here's how to manually set one of the filter's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel.params['outlier_detection']['nb_reject'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select a subset of the data for calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tini = '15 January 2018'\n",
    "Tfin = '15 February 2018'\n",
    "\n",
    "channel.calib = {'start': Tini, 'end': Tfin}\n",
    "start = channel.calib['start']\n",
    "end = channel.calib['end']\n",
    "# Plot calibration data\n",
    "title = 'Calibration subset'\n",
    "\n",
    "calib_data = channel.raw_data[start:end]\n",
    "\n",
    "PlottingTools.plotUnivar_plotly(channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test the dataset for missing values, NaN, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = DataCoherence.data_coherence(channel)\n",
    "flag"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fix issues with the calibration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = DataCoherence.resample(channel, '2 min')\n",
    "channel = DataCoherence.fillna(channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try the data coherence check again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = DataCoherence.data_coherence(channel)\n",
    "flag"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OK, we're good to go!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtration_method = \"Online_EWMA\"\n",
    "channel.params['outlier_detection']['method'] = filtration_method\n",
    "\n",
    "channel = OutlierDetection.outlier_detection(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlottingTools.plotOutliers_plotly(channel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Data smoother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "channel.params['data_smoother']['h_smoother'] = 10\n",
    "\n",
    "channel = Smoother.kernel_smoother(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlottingTools.plotOutliers_plotly(channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fault detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum real expected value of the variable\n",
    "channel.params['fault_detection_uni']['range_min'] = 50\n",
    "\n",
    "# maximum real expected value of the variable\n",
    "channel.params['fault_detection_uni']['range_max'] = 550\n",
    "\n",
    "# Definition limit of scores:\n",
    "channel.params['fault_detection_uni']['corr_min'] = -50\n",
    "channel.params['fault_detection_uni']['corr_max'] = 50\n",
    "\n",
    "# minimum expected slope based on good data series\n",
    "channel.params['fault_detection_uni']['slope_min'] = -10\n",
    "\n",
    "# maximum expected slope based on a good data series\n",
    "channel.params['fault_detection_uni']['slope_max'] = 10\n",
    "\n",
    "# Minimum variation between accepted data and smoothed data\n",
    "channel.params['fault_detection_uni']['std_min'] = -10\n",
    "\n",
    "# Maximum variation between accepted data and smoothed data\n",
    "channel.params['fault_detection_uni']['std_max'] = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul Q_corr, Q_std, Q_slope, Q_range:\n",
    "channel = FaultDetection.D_score(channel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Treated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the treated data and the deleted data:\n",
    "channel = TreatedData.TreatedD(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the raw data and treated data:\n",
    "PlottingTools.plotTreatedD_plotly(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of outliers and deleted data\n",
    "filtration_method = channel.info['current_filtration_method']\n",
    "print(channel.info['filtration_results'][filtration_method])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}